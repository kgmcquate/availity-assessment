name: Deploy Spark job JAR to S3

on:
  push:
    branches: ["main"]
  workflow_dispatch:

env:
  AWS_REGION: "us-east-1"
  AWS_ACCOUNT_ID: "117819748843"

jobs:
  build-jar:
    runs-on: ubuntu-latest
    container:
      image: sbtscala/scala-sbt:eclipse-temurin-focal-11.0.22_7_1.9.9_2.12.19

    steps:
    - uses: actions/checkout@v4

    - run: sbt assembly

    - uses: actions/upload-artifact@v4
      with:
        name: assembly-jar
        path: target/scala-*/*

  deploy-jar:
    needs: build-jar
    runs-on: ubuntu-latest
    container:
      image: python:3.11

    steps:
    - uses: actions/download-artifact@v4
      with:
        name: assembly-jar

    - uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - run: pip install awscli

    - run: ls -la

    - run: aws s3 cp scala-*/*.jar s3://deployment-zone-${AWS_ACCOUNT_ID}/availity_assessment/
